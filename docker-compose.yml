services:
  # ===========================================
  # Frontend - Next.js
  # ===========================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_WS_URL=ws://localhost:8000
    depends_on:
      - backend
    networks:
      - voiceai-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'

  # ===========================================
  # Backend - FastAPI
  # ===========================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: voiceai-backend
    user: "1000:1000"
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - ULTRAVOX_WEBHOOK_URL=${ULTRAVOX_WEBHOOK_URL:-http://localhost:8000/api/v1/webhooks/ultravox}
    volumes:
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - voiceai-network
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'

  # ===========================================
  # Celery Worker
  # ===========================================
  celery-worker:
    image: voiceai-backend
    user: "1000:1000"
    env_file:
      - .env
    volumes:
      - ./backend:/app
    depends_on:
      - backend
      - redis
    networks:
      - voiceai-network
    command: celery -A app.tasks.celery_tasks:celery_app worker --loglevel=info --concurrency=10
    healthcheck:
      test: ["CMD", "celery", "-A", "app.tasks.celery_tasks:celery_app", "inspect", "ping", "--timeout", "5"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'

  # ===========================================
  # Celery Beat (Scheduler)
  # ===========================================
  celery-beat:
    image: voiceai-backend
    user: "1000:1000"
    env_file:
      - .env
    volumes:
      - ./backend:/app
    depends_on:
      - celery-worker
    networks:
      - voiceai-network
    command: celery -A app.tasks.celery_tasks:celery_app beat --loglevel=info --schedule=/tmp/celerybeat-schedule
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  # ===========================================
  # PostgreSQL Database (with pgvector for RAG)
  # ===========================================
  postgres:
    image: pgvector/pgvector:pg16
    restart: unless-stopped
    # No host port exposure - only accessible within Docker network
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}
      POSTGRES_DB: ${POSTGRES_DB:-voiceai}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - voiceai-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'

  # ===========================================
  # Redis
  # ===========================================
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    # No host port exposure - only accessible within Docker network
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-changeme}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - voiceai-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-changeme}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'

  # ===========================================
  # Asterisk PBX
  # ===========================================
  asterisk:
    build:
      context: ./asterisk
      dockerfile: Dockerfile
    ports:
      - "5043:5043/udp"
      - "5043:5043/tcp"
      # 5061 removed - not needed, security risk
      - "10000-10100:10000-10100/udp"
      # 8088 (ARI) is internal only - backend connects via Docker network
    volumes:
      - asterisk-recordings:/var/spool/asterisk/recording
    environment:
      - ARI_USERNAME=${ASTERISK_ARI_USER:?ASTERISK_ARI_USER is required}
      - ARI_PASSWORD=${ASTERISK_ARI_PASSWORD:?ASTERISK_ARI_PASSWORD is required}
    env_file:
      - .env
    networks:
      - voiceai-network
    cap_add:
      - NET_ADMIN
    security_opt:
      - no-new-privileges:true
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'

  # ===========================================
  # Asterisk AudioSocket Bridge (OpenAI provider only)
  # Not used when agent.provider = "ultravox"
  # ===========================================
  asterisk-bridge:
    image: voiceai-backend
    user: "1000:1000"
    # Port 9092 is internal only - asterisk connects via Docker network
    env_file:
      - .env
    volumes:
      - ./backend:/app
    environment:
      - AUDIOSOCKET_HOST=0.0.0.0
      - AUDIOSOCKET_PORT=9092
      - MAX_CONCURRENT_CALLS=50
      - REALTIME_MODEL=gpt-realtime-mini
    networks:
      - voiceai-network
    command: python -m app.services.asterisk_bridge
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(3); s.connect(('127.0.0.1',9092)); s.close()"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'

  # ===========================================
  # MinIO (Object Storage)
  # ===========================================
  minio:
    image: minio/minio:RELEASE.2024-06-13T22-53-53Z
    restart: unless-stopped
    # Console (9001) and API (9000) are internal only - nginx proxies in prod
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:?MINIO_ROOT_PASSWORD is required}
    volumes:
      - minio-data:/data
    networks:
      - voiceai-network
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'

  # ===========================================
  # Nginx (Production)
  # ===========================================
  # nginx:
  #   image: nginx:alpine
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf
  #     - ./nginx/ssl:/etc/nginx/ssl
  #   depends_on:
  #     - frontend
  #     - backend
  #   networks:
  #     - voiceai-network

  # ===========================================
  # Ollama - Local LLM Server
  # ===========================================
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - voiceai-network
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 6G
          cpus: '4.0'

  # ===========================================
  # Piper TTS - Local Text-to-Speech
  # ===========================================
  piper:
    image: rhasspy/wyoming-piper:latest
    restart: unless-stopped
    command: >
      --piper /usr/share/piper/piper
      --voice tr_TR-dfki-medium
      --length-scale 1.0
      --noise-scale 0.667
      --noise-w 0.8
      --max-piper-procs 2
      --data-dir /data
      --download-dir /data
    volumes:
      - piper-data:/data
    networks:
      - voiceai-network
    healthcheck:
      test: ["CMD-SHELL", "echo | nc -w 3 127.0.0.1 10200 || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'

  # ===========================================
  # Pipeline AudioSocket Bridge (Local STT+LLM+TTS)
  # Same architecture as asterisk-bridge but uses local models
  # ===========================================
  pipeline-bridge:
    image: voiceai-backend
    user: "1000:1000"
    env_file:
      - .env
    volumes:
      - ./backend:/app
      - faster-whisper-cache:/home/appuser/.cache
    environment:
      - PIPELINE_AUDIOSOCKET_HOST=0.0.0.0
      - PIPELINE_AUDIOSOCKET_PORT=9093
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2.5:7b}
      - PIPER_HOST=piper
      - PIPER_PORT=10200
      - FASTER_WHISPER_MODEL=${FASTER_WHISPER_MODEL:-base}
      - FASTER_WHISPER_DEVICE=cpu
      - FASTER_WHISPER_COMPUTE=int8
      - MAX_CONCURRENT_CALLS=10
    networks:
      - voiceai-network
    command: python -m app.services.pipeline_bridge
    depends_on:
      ollama:
        condition: service_healthy
      piper:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(3); s.connect(('127.0.0.1',9093)); s.close()"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '4.0'

networks:
  voiceai-network:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
  minio-data:
  asterisk-recordings:
  ollama-data:
  piper-data:
  faster-whisper-cache:
